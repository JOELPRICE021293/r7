{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Marijse\n",
    "\n",
    "Aim: \n",
    "- Load the original data from the WR database from csv into a local postgres instance; \n",
    "- Load the different data views created from the original data from csv into a local postgres instance;\n",
    "\n",
    "Prerequisites: \n",
    "- Have all csv files loaded into the folder _6_data_clean & folder _10_data_views;\n",
    "- Have a local PSQL instance set up with a designated database for the rugby. Ensure that you know the password of your postgres user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\jprice\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\jprice\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "# sqlalchemy and psycopg2 might not be pre-installed, so we will run the installation of these packages first\n",
    "! pip install psycopg2\n",
    "! pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary python packages to be able to run the code that follows\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the below connection details based on your own psql connection details. \n",
    "# Note that the details are case sensitive. \n",
    "\n",
    "# Set up the database connection wiht Psycopg2. Adjust the dbname, user and password. \n",
    "db = psycopg2.connect(dbname='databasename you have given', user='postgres', password= 'password of database')\n",
    "cursor=db.cursor()\n",
    "\n",
    "# Set up a database connection using sqlalchemy. The first commented line explains what the different part of the \n",
    "# string stand for. Using this, adjust the user, password, port and dbname.  \n",
    "#engine = create_engine('postgres://user:password@localhost:port/database_name)\n",
    "engine = create_engine('postgres://postgres:password@localhost:5432/dbname')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up the psql database schema structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "# Define the input and output strings \n",
    "# The file path might need to be updated depending on where/how the files get stored. If you are working on a windows\n",
    "# system, comment out the below two lines and uncomment the lines for Windows underneath. \n",
    "# input_string1 = '../_6_data_clean/'\n",
    "# input_string2 = '../_10_data_views/'\n",
    "\n",
    "# Windows string :\n",
    "input_string1 = 'C:\\\\Users\\\\aadams\\\\Downloads\\\\Rugby7s\\\\_6_data_clean\\\\'\n",
    "input_string2 = 'C:\\\\Users\\\\aadams\\\\Downloads\\\\Rugby7s\\\\_10_data_views\\\\'\n",
    "\n",
    "# Define the schema names. We will create these in Postgres. For consistency and to enable us to share code easier, \n",
    "# please do not change thes. \n",
    "schema1 = '_0_original_data'\n",
    "schema2 = '_1_data_views'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the schemas in postgres. \n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS \" + schema1)\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS \" + schema2)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the different original csv files into psql (schema1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\all_time_head_to_head.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\event_tables.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\full_squads.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\management.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\match_fixtures.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\player_records_in_event.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\player_records_in_event_all_time.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\player_records_match_record_in_event.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\player_records_match_record_in_event_all_time.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\team_data_per_tournament.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\team_dictionary.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\team_match_records_in_event.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\team_match_records_in_event_all_time.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\team_records_in_event.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\team_record_in_event_all_time.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\terminology_dictionary.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_6_data_clean\\\\tournament_id_dictionary.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the files in the first input_string into the 'files' object. These files will go in the _0_original_data schema. \n",
    "files = glob.glob(input_string1 + \"**/*.csv\", recursive=True)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_time_head_to_head\n",
      "event_tables\n",
      "full_squads\n",
      "management\n",
      "match_fixtures\n",
      "player_records_in_event\n",
      "player_records_in_event_all_time\n",
      "player_records_match_record_in_event\n",
      "player_records_match_record_in_event_all_time\n",
      "team_data_per_tournament\n",
      "team_dictionary\n",
      "team_match_records_in_event\n",
      "team_match_records_in_event_all_time\n",
      "team_records_in_event\n",
      "team_record_in_event_all_time\n",
      "terminology_dictionary\n",
      "tournament_id_dictionary\n"
     ]
    }
   ],
   "source": [
    "# we create an empty table for each file\n",
    "for k in files:\n",
    "    \n",
    "    # Set up the database connection wiht Psycopg2\n",
    "    db = psycopg2.connect(dbname='databasename you have given', user='postgres', password= 'password of database')\n",
    "    cursor=db.cursor()\n",
    "\n",
    "    # Set up a database connection using sqlalchemy\n",
    "    engine = create_engine('postgres://postgres:password@localhost:5432/dbname')\n",
    "    \n",
    "    # We extract the tablename from the csv_file\n",
    "    #table_name = k.split('/')[2].split('.')[0]\n",
    "    \n",
    "    #for windows only:\n",
    "    table_name = k.split('\\\\')[6].split('.')[0]\n",
    "\n",
    "    print(table_name)\n",
    "    \n",
    "    # We load the csv into a df \n",
    "    df = pd.read_csv(k)\n",
    "    \n",
    "    # We clean up the column headers a bit\n",
    "    dict_columns = {}\n",
    "    for x in (df.columns.values):\n",
    "        dict_columns[x] = x.lower().replace(' ','_').replace(':','').replace('group','pool')\n",
    "    df = df.rename(columns=dict_columns)\n",
    "    \n",
    "    # We create an empty table with the table name\n",
    "    df.to_sql(schema=schema1, con=engine, if_exists='append', name=table_name, index=False)\n",
    "    \n",
    "    # We drop the column 'Unnamed: 0' if it exists\n",
    "    cursor.execute(\"alter table \"+ schema1 +\".\"+table_name+\" drop column if exists unnamed_0\",db)\n",
    "\n",
    "    db.commit()\n",
    "    db.close()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the different csv views on the data into psql (schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_10_data_views\\\\fixtures_with_player_stats_full.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_10_data_views\\\\match_fixtures_features_row_per_team.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_10_data_views\\\\match_fixtures_full_row_per_match.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_10_data_views\\\\player_stats_full.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_10_data_views\\\\points_by_team_by_tournament.csv',\n",
       " 'C:\\\\Users\\\\jprice\\\\Desktop\\\\Rugby\\\\_10_data_views\\\\team_data_with_timezone.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the files in the second input_string into the 'files' object. These files will go in the _1_data_views schema. \n",
    "files = glob.glob(input_string2 + \"**/*.csv\", recursive=True)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixtures_with_player_stats_full\n",
      "match_fixtures_features_row_per_team\n",
      "match_fixtures_full_row_per_match\n",
      "player_stats_full\n",
      "points_by_team_by_tournament\n",
      "team_data_with_timezone\n"
     ]
    }
   ],
   "source": [
    "# we create an empty table for each file\n",
    "for k in files:\n",
    "    \n",
    "    # Set up the database connection wiht Psycopg2\n",
    "    db = psycopg2.connect(dbname='databasename you have given', user='postgres', password= 'password of database')\n",
    "    cursor=db.cursor()\n",
    "\n",
    "    # Set up a database connection using sqlalchemy\n",
    "    engine = create_engine('postgres://postgres:password@localhost:5432/dbname')\n",
    "    \n",
    "    # We extract the tablename from the csv_file\n",
    "    #table_name = k.split('/')[2].split('.')[0]\n",
    "\n",
    "    #for windows only:\n",
    "    table_name = k.split('\\\\')[6].split('.')[0]\n",
    "    \n",
    "    print(table_name)\n",
    "    \n",
    "    # We load the csv into a df \n",
    "    df = pd.read_csv(k)\n",
    "    \n",
    "    # We clean up the column headers a bit\n",
    "    dict_columns = {}\n",
    "    for x in (df.columns.values):\n",
    "        dict_columns[x] = x.lower().replace(' ','_').replace(':','').replace('group','pool')\n",
    "    df = df.rename(columns=dict_columns)\n",
    "    \n",
    "    # We create an empty table with the table name\n",
    "    df.to_sql(schema=schema2, con=engine, if_exists='append', name=table_name, index=False)\n",
    "    \n",
    "    # We drop the column 'Unnamed: 0' if it exists\n",
    "    cursor.execute(\"alter table \"+ schema2 +\".\"+table_name+\" drop column if exists unnamed_0\",db)\n",
    "\n",
    "    db.commit()\n",
    "    db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
