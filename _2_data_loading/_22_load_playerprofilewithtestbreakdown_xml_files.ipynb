{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # World Rugby XML Parsing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code parses the xml files and saves them to csv / sql database.\n",
    "\n",
    "Author/creator: Joel Huang\n",
    "Title: World Rugby XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prase PersonnelProfileWithAppearances xml files and save them to csv / sql database.\n",
    "import xml.etree.ElementTree as et\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import sqlalchemy as sa\n",
    "    \n",
    "res = []\n",
    "\n",
    "def compute_xml_data(lst,elem, func, level=0):\n",
    "    func(lst,elem,level)\n",
    "    for child in elem.getchildren():\n",
    "        compute_xml_data(lst,child, func, level+1)\n",
    "\n",
    "def gather_level(lst,elem,level):\n",
    "    lst.append(('-'*level+elem.tag, elem.text))\n",
    "\n",
    "xml_files = glob.glob('./*.xml')\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    lst = []\n",
    "    root = et.parse(xml_file)\n",
    "    compute_xml_data(lst,root.getroot(), gather_level)\n",
    "    res.append(lst)\n",
    "\n",
    "def get_table_names(xml_data_list): \n",
    "    table_names = []\n",
    "    for t in xml_data_list:\n",
    "        if t[0]:\n",
    "            if re.match(r'(-{http://webservices.irb.com/}\\w)', t[0], re.IGNORECASE):\n",
    "                name = t[0][30:].strip()\n",
    "                table_names.append(name)\n",
    "    return table_names\n",
    "                \n",
    "tables = get_table_names(res[0])\n",
    "\n",
    "for xml_file in xml_files:\n",
    "    lst = []\n",
    "    root = et.parse(xml_file)\n",
    "    compute_xml_data(lst,root.getroot(), gather_level)\n",
    "\n",
    "# build all the dataframe for the xml\n",
    "def build_xml_dfs(xmls):\n",
    "    personID_tag = '-{http://webservices.irb.com/}PersonID'\n",
    "    personnel_profile_with_appearances_tag = '{http://webservices.irb.com/}PersonnelProfileWithAppearances'\n",
    "    teamsRepresented_tag = '-{http://webservices.irb.com/}TeamsRepresented'\n",
    "    team_tag = '--{http://webservices.irb.com/}Team'\n",
    "    testBreakdown_tag = '-{http://webservices.irb.com/}TestBreakdown'\n",
    "    eventAppearances_tag = '-{http://webservices.irb.com/}EventAppearances'\n",
    "    appearance_tag = '--{http://webservices.irb.com/}Appearance'\n",
    "    testAppearances_tag = '-{http://webservices.irb.com/}TestAppearances'\n",
    "    testAppearance_tag = '--{http://webservices.irb.com/}TestAppearance'\n",
    "    \n",
    "    personID_idx = [xml[0] for xml in xmls].index(personID_tag)\n",
    "    personID = xmls[personID_idx][1]\n",
    "    \n",
    "    personnel_profile_with_appearances_list = []\n",
    "    teamsRepresented_list = []\n",
    "    testBreakdown_list = []\n",
    "    eventAppearances_list = []\n",
    "    testAppearances_list = []\n",
    "    \n",
    "    for t in xmls:\n",
    "        if t[0] == personnel_profile_with_appearances_tag: \n",
    "            personnel_profile_with_appearances_start_idx = [xml[0] for xml in xmls].index(personnel_profile_with_appearances_tag)\n",
    "            teamsRepresented_start_idx = [xml[0] for xml in xmls].index(teamsRepresented_tag)\n",
    "            testBreakdown_start_idx = [xml[0] for xml in xmls].index(testBreakdown_tag)\n",
    "            eventAppearances_start_idx = [xml[0] for xml in xmls].index(eventAppearances_tag)\n",
    "            testAppearances_start_idx = [xml[0] for xml in xmls].index(testAppearances_tag)\n",
    "\n",
    "            for m in xmls[personnel_profile_with_appearances_start_idx+1:teamsRepresented_start_idx]:\n",
    "                if m[0] is not teamsRepresented_tag:\n",
    "                    personnel_profile_with_appearances_list.append((m[0][30:].strip(),m[1]))\n",
    "                else:\n",
    "                    continue\n",
    "            for o in xmls[teamsRepresented_start_idx+1:testBreakdown_start_idx]:\n",
    "                if o[0] == team_tag:\n",
    "                    sub_list = []\n",
    "                    sub_list.append(('PersonID',personID))\n",
    "                    teamsRepresented_list.append(sub_list)\n",
    "                elif o[0] is not testBreakdown_tag:\n",
    "                    sub_list.append((o[0][32:].strip(),o[1]))\n",
    "                else:\n",
    "                    continue\n",
    "            for t1 in xmls[testBreakdown_start_idx+1:eventAppearances_start_idx]:\n",
    "                if t1[0] == team_tag:\n",
    "                    sub_list = []\n",
    "                    sub_list.append(('PersonID',personID))\n",
    "                    testBreakdown_list.append(sub_list)\n",
    "                elif t1[0] is not eventAppearances_tag:\n",
    "                    sub_list.append((t1[0][32:].strip(),t1[1]))\n",
    "                else:\n",
    "                    continue\n",
    "            for t2 in xmls[eventAppearances_start_idx+1:testAppearances_start_idx]:\n",
    "                if t2[0] == appearance_tag:\n",
    "                    sub_list = []\n",
    "                    sub_list.append(('PersonID',personID))\n",
    "                    eventAppearances_list.append(sub_list)\n",
    "                elif t2[0] is not eventAppearances_tag:\n",
    "                    sub_list.append((t2[0][32:].strip(),t2[1]))\n",
    "                else:\n",
    "                    continue\n",
    "            for time_line in xmls[testAppearances_start_idx+1:]:\n",
    "                if time_line[0] == testAppearance_tag:\n",
    "                    sub_list = []\n",
    "                    sub_list.append(('PersonID',personID))\n",
    "                    testAppearances_list.append(sub_list)\n",
    "                elif time_line[0]:\n",
    "                    sub_list.append((time_line[0][32:].strip(),time_line[1]))\n",
    "                else:\n",
    "                    break                 \n",
    "\n",
    "    records_dict = {'personnel_profile_with_appearances': personnel_profile_with_appearances_list, 'teamsRepresented': teamsRepresented_list, 'testBreakdown': testBreakdown_list, 'eventAppearances':eventAppearances_list,'testAppearances':testAppearances_list}\n",
    "    personnel_profile_with_appearances_df = pd.DataFrame.from_records(personnel_profile_with_appearances_list).transpose()\n",
    "    personnel_profile_with_appearances_df = personnel_profile_with_appearances_df.rename(columns=personnel_profile_with_appearances_df.iloc[0]).drop(personnel_profile_with_appearances_df.index[0])\n",
    "\n",
    "    teamsRepresented_df = [pd.DataFrame.from_records(lst).transpose() for lst in teamsRepresented_list if lst]\n",
    "    teamsRepresented_df = [df.rename(columns=df.iloc[0]).drop(df.index[0]) for df in teamsRepresented_df]\n",
    "\n",
    "    testBreakdown_df = [pd.DataFrame.from_records(lst).transpose() for lst in testBreakdown_list if lst]\n",
    "    testBreakdown_df = [df.rename(columns=df.iloc[0]).drop(df.index[0]) for df in testBreakdown_df ]\n",
    "    \n",
    "    eventAppearances_df = [pd.DataFrame.from_records(lst).transpose() for lst in eventAppearances_list if lst]\n",
    "    eventAppearances_df = [df.rename(columns=df.iloc[0]).drop(df.index[0]) for df in eventAppearances_df]\n",
    "    \n",
    "    testAppearances_df = [pd.DataFrame.from_records(lst).transpose() for lst in testAppearances_list if lst]\n",
    "    testAppearances_df = [df.rename(columns=df.iloc[0]).drop(df.index[0]) for df in testAppearances_df]\n",
    "    \n",
    "    personnel_profile_with_appearances_dfs_merged = personnel_profile_with_appearances_df\n",
    "    if teamsRepresented_df: \n",
    "        teamsRepresented_dfs_merged = pd.concat(teamsRepresented_df)\n",
    "    else:\n",
    "        teamsRepresented_dfs_merged = pd.DataFrame()\n",
    "    if testBreakdown_df:\n",
    "        testBreakdown_dfs_merged = pd.concat(testBreakdown_df)\n",
    "    else:\n",
    "        testBreakdown_dfs_merged = pd.DataFrame()\n",
    "    if eventAppearances_df:\n",
    "        eventAppearances_dfs_merged = pd.concat(eventAppearances_df)\n",
    "    else:\n",
    "        eventAppearances_dfs_merged = pd.DataFrame()\n",
    "    if testAppearances_df:\n",
    "        testAppearances_dfs_merged = pd.concat(testAppearances_df)\n",
    "    else:\n",
    "        testAppearances_dfs_merged = pd.DataFrame()\n",
    "    \n",
    "    return {'personnel_profile_with_appearances':personnel_profile_with_appearances_dfs_merged,\n",
    "            'teamsRepresented':teamsRepresented_dfs_merged,\n",
    "            'testBreakdown':testBreakdown_dfs_merged,\n",
    "            'eventAppearances':eventAppearances_dfs_merged,\n",
    "            'testAppearances':testAppearances_dfs_merged}\n",
    "\n",
    "all_xml_dfs = []\n",
    "personnel_profile_with_appearances_dfs_list = []\n",
    "teamsRepresented_dfs_list = []\n",
    "testBreakdown_dfs_list = []\n",
    "eventAppearances_dfs_list = []\n",
    "testAppearances_dfs_list = []\n",
    "\n",
    "for xml_data in res:\n",
    "    all_xml_dfs.append(build_xml_dfs(xml_data))\n",
    "\n",
    "for df_dict in all_xml_dfs:\n",
    "    for k,v in df_dict.items():\n",
    "        if k == 'personnel_profile_with_appearances':\n",
    "            personnel_profile_with_appearances_dfs_list.append(v)\n",
    "        if k == 'teamsRepresented':\n",
    "            teamsRepresented_dfs_list.append(v)\n",
    "        if k == 'testBreakdown':\n",
    "            testBreakdown_dfs_list.append(v)\n",
    "        if k == 'eventAppearances':\n",
    "            eventAppearances_dfs_list.append(v)\n",
    "        if k == 'testAppearances':\n",
    "            testAppearances_dfs_list.append(v)\n",
    "\n",
    "if personnel_profile_with_appearances_dfs_list:\n",
    "    personnel_profile_with_appearances_dfs_merged_all = pd.concat(personnel_profile_with_appearances_dfs_list)\n",
    "else:\n",
    "    personnel_profile_with_appearances_dfs_merged_all = pd.DataFrame()\n",
    "if teamsRepresented_dfs_list:\n",
    "    teamsRepresented_dfs_merged_all = pd.concat(teamsRepresented_dfs_list)\n",
    "else: \n",
    "    teamsRepresented_dfs_merged_all = pd.DataFrame()\n",
    "if testBreakdown_dfs_list:\n",
    "    testBreakdown_dfs_merged_all = pd.concat(testBreakdown_dfs_list)\n",
    "else:\n",
    "    testBreakdown_dfs_merged_all = pd.DataFrame()\n",
    "if eventAppearances_dfs_list:\n",
    "    eventAppearances_dfs_merged_all = pd.concat(eventAppearances_dfs_list)\n",
    "else: \n",
    "    eventAppearances_dfs_merged_all = pd.DataFrame()\n",
    "if testAppearances_dfs_list:\n",
    "    testAppearances_dfs_merged_all = pd.concat(testAppearances_dfs_list)\n",
    "else:\n",
    "    testAppearances_dfs_merged_all = pd.DataFrame()\n",
    "\n",
    "# load dataframe into Postgres\n",
    "def write_data_to_sql(df, table_name):        \n",
    "    try:\n",
    "        engine = sa.create_engine(connection_string, echo=True);\n",
    "        # add a table id?\n",
    "        # df[\"TableId\"] = tableId;\n",
    "        if not df.empty:\n",
    "            df.to_sql(tablename, engine, if_exists='append', index=False)       \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "personnel_profile_with_appearances_dfs_merged_all.to_csv('../_3_data_clean/playerprofilewithtestbreakdown_personnelprofilewithappearances.csv',index=False)\n",
    "teamsRepresented_dfs_merged_all.to_csv('../_3_data_clean/playerprofilewithtestbreakdown_teamsrepresented.csv',index=False)\n",
    "testBreakdown_dfs_merged_all.to_csv('../_3_data_clean/playerprofilewithtestbreakdown_testbreakdown.csv',index=False)\n",
    "eventAppearances_dfs_merged_all.to_csv('../_3_data_clean/playerprofilewithtestbreakdown_eventappearances.csv',index=False)\n",
    "testAppearances_dfs_merged_all.to_csv('../_3_data_clean/playerprofilewithtestbreakdown_testappearances.csv',index=False)\n",
    "print('Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run below script to find out the xml format, only run if format is due to change. \n",
    "import xml.etree.ElementTree as et\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import sqlalchemy as sa\n",
    "    \n",
    "res = []\n",
    "\n",
    "def compute_xml_data(elem, func, level=0):\n",
    "    func(elem,level)\n",
    "    for child in elem.getchildren():\n",
    "        compute_xml_data(child, func, level+1)\n",
    "\n",
    "def gather_level(elem,level):\n",
    "    print('-'*level+elem.tag, elem.text)\n",
    "#     res.append(('-'*level+elem.tag, elem.text))\n",
    "\n",
    "xml_files = glob.glob('./*.xml')\n",
    "xml_file = xml_files[0]\n",
    "root = et.parse(xml_file) \n",
    "xml_data = compute_xml_data(root.getroot(), gather_level)\n",
    "\n",
    "def get_table_names(xml_data_list): \n",
    "    table_names = []\n",
    "    for t in xml_data_list:\n",
    "        if t[0]:\n",
    "            if re.match(r'(-{http://webservices.irb.com/}\\w)', t[0], re.IGNORECASE):\n",
    "                name = t[0][30:].strip()\n",
    "                table_names.append(name)\n",
    "    return table_names\n",
    "\n",
    "# print(res)\n",
    "\n",
    "print(get_table_names(res))\n",
    "\n",
    "# compute_xml_data(root.getroot(), gather_level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
