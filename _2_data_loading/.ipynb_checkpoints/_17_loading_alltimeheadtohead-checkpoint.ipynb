{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Marijse\n",
    "\n",
    "Question to Pierre: The 'all time team match record vs opponent' seems empty? Similar view arises for the 'All time team match record' table. \n",
    "\n",
    "Table URL: http://webservices.irb.com/EventInformation.asmx/AllTimeHeadtoHead\n",
    "\n",
    "Required fiels:\n",
    "- UID\n",
    "- EventID\n",
    "- Team1ID\n",
    "- Team2ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "import requests\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the database connection wiht Psycopg2\n",
    "db = psycopg2.connect(dbname='Rugby', user='postgres', host='localhost', password='password')\n",
    "cursor=db.cursor()\n",
    "\n",
    "# Set up a database connection using sqlalchemy\n",
    "engine = create_engine('postgres://postgres:password@localhost:5432/Rugby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "\n",
    "# Define the input and output strings\n",
    "input_string = '../_1_data_extracts/squad/'\n",
    "output_strig = '../_3_data_clean/'\n",
    "\n",
    "# Define schemas\n",
    "schema1 = '_0_original_data'\n",
    "schema2 = '_1_data_views'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS \" + schema1)\n",
    "cursor.execute(\"CREATE SCHEMA IF NOT EXISTS \" + schema2)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Match Fixtures into datafrmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: we run the function\n",
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data) # element tree\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for subchild in child:\n",
    "            record[subchild.tag] = subchild.text\n",
    "            all_records.append(record)\n",
    "    return pd.DataFrame(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List all event id's of the past two years\n",
    "eventid = pd.read_sql_query('select eventid from _0_original_data.tournament_id_dictionary',db)\n",
    "eventid_list = list(eventid.eventid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an empty dataframe to append the different xml files to\n",
    "all_time_head_to_head = pd.DataFrame()\n",
    "\n",
    "#eventid_list = ['1611']\n",
    "\n",
    "for k in eventid_list:\n",
    "    \n",
    "    print('the tournament id is ' + k)\n",
    "    \n",
    "    teamid = pd.read_sql_query(\"select team1id from _0_original_data.match_fixtures where tournament_id = '\"+k+\"'\",db)\n",
    "    teamid_list = list(teamid.team1id.unique())\n",
    "    \n",
    "    for n in teamid_list:\n",
    "    \n",
    "        opponentid = pd.read_sql_query(\"select team2id from _0_original_data.match_fixtures \\\n",
    "                                         where tournament_id = '\"+k+\"' and team1id = '\"+n+\"'\",db)\n",
    "        opponentid_list = list(opponentid.team2id.unique())\n",
    "        \n",
    "        print('the team1id is ' +n)\n",
    "    \n",
    "        for m in opponentid_list:\n",
    "            \n",
    "            print('the team2id is ' + m)\n",
    "                            \n",
    "            url = 'http://webservices.irb.com/EventInformation.asmx/AllTimeHeadtoHead?uid=e9656db8-ffb5-4115-ac0b-cbd5688e6648&eventid='+k+'&team1id='+n+'&team2id='+m\n",
    "            response = urllib.request.urlopen(url)\n",
    "            data = response.read()      \n",
    "            text = data.decode('utf-8') \n",
    "        \n",
    "            # Create a df which equals the text object\n",
    "            df = xml2df(text)\n",
    "            \n",
    "            # Skip all empty Event ID's\n",
    "            if df.empty == True:\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "            print('we got this far')\n",
    "\n",
    "            # Extract the tournament id from the file name\n",
    "            tournament_id =  k\n",
    "            team1id = m\n",
    "            team2id = n\n",
    "        \n",
    "            # Set a column equal to the file name\n",
    "            df['tournament_id'] = tournament_id\n",
    "            df['team1id'] = team1id\n",
    "            df['team2id'] = team2id\n",
    "\n",
    "            # Clean the column headers \n",
    "            dict_columns={}\n",
    "            for x in (df.columns.values):\n",
    "                dict_columns[x] = x.lower().replace('{http://webservices.irb.com/}','')\n",
    "            df_clean = df.rename(columns=dict_columns)\n",
    "    \n",
    "            # remove duplicates from the data\n",
    "            df_clean = df_clean.drop_duplicates(['tournament_id','team1id','team2id'], keep='first')\n",
    "        \n",
    "            # Append each individual dataframe to the full_fixtures df\n",
    "            frames =(all_time_head_to_head,df_clean)\n",
    "            all_time_head_to_head = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_head_to_head.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final table includes 20 tournaments and has 2680 records associated with 8 methods over the 20 different tournaments. \n",
    "all_time_head_to_head.tournament_id.nunique()\n",
    "all_time_head_to_head.team1id.nunique()\n",
    "len(all_time_head_to_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract to CSV\n",
    "all_time_head_to_head.to_csv('../_3_data_clean/all_time_head_to_head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract to SQL\n",
    "table_name = 'all_time_head_to_head'\n",
    "all_time_head_to_head.to_sql(schema=schema1, con=engine, if_exists='replace', name=table_name)\n",
    "db.commit\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
